# ğŸ”§ è¿ç»´æ“ä½œæŒ‡å—

## ğŸš€ æœ¬åœ°å¼€å‘ç¯å¢ƒ

### ç¯å¢ƒè¦æ±‚
```bash
# å¿…éœ€è½¯ä»¶ç‰ˆæœ¬
Node.js >= 18.0.0
pnpm >= 8.0.0
PostgreSQL >= 15.0 (with pgvector extension)
Redis >= 6.0
Docker >= 20.10 (å¯é€‰ï¼Œç”¨äºå¤–éƒ¨æœåŠ¡)
```

### å¿«é€Ÿå¯åŠ¨
```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository>
cd study-assistant

# 2. å®‰è£…ä¾èµ–
pnpm install

# 3. å¯åŠ¨å¤–éƒ¨æœåŠ¡ (PostgreSQL + Redis + MinIO)
npm run docker:up

# 4. é…ç½®ç¯å¢ƒå˜é‡
cp packages/db/.env.example packages/db/.env
# ç¼–è¾‘ .env æ–‡ä»¶é…ç½®æ•°æ®åº“è¿æ¥

# 5. åˆå§‹åŒ–æ•°æ®åº“
npm run db:migrate
npm run db:seed

# 6. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev
```

### å¼€å‘æœåŠ¡å™¨ç«¯å£
- **Webå‰ç«¯**: http://localhost:3000
- **APIæœåŠ¡**: http://localhost:4000  
- **PostgreSQL**: localhost:5432
- **Redis**: localhost:6379
- **MinIO**: http://localhost:9000

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®

### å¿…éœ€çš„ç¯å¢ƒå˜é‡
```bash
# packages/db/.env
# =================

# åŸºç¡€ç¯å¢ƒ
NODE_ENV=development
PORT=3000
API_PORT=4000

# æ•°æ®åº“é…ç½®
DATABASE_URL="postgresql://postgres:postgres123@localhost:5432/study_assistant"

# Redisé…ç½®
REDIS_URL="redis://localhost:6379"

# æ–‡ä»¶å­˜å‚¨ (MinIO)
STORAGE_TYPE=minio
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123
MINIO_BUCKET_NAME=study-assistant
MINIO_USE_SSL=false

# AIæœåŠ¡é…ç½® (å¿…é¡»é…ç½®çœŸå®API Key)
OPENAI_API_KEY=sk-proj-ä½ çš„OpenAI-API-Key
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL_CHAT=gpt-3.5-turbo
OPENAI_MODEL_EMBEDDING=text-embedding-ada-002

# NextAuth.jsè®¤è¯
NEXTAUTH_SECRET=dev-secret-key-change-in-production
NEXTAUTH_URL=http://localhost:3000
JWT_SECRET=dev-jwt-secret-key

# Google OAuth (å¯é€‰)
GOOGLE_CLIENT_ID=ä½ çš„Google-Client-ID
GOOGLE_CLIENT_SECRET=ä½ çš„Google-Client-Secret
```

### ç”Ÿäº§ç¯å¢ƒé¢å¤–é…ç½®
```bash
# ç”Ÿäº§ç¯å¢ƒç‰¹æœ‰
NODE_ENV=production
NEXTAUTH_URL=https://your-domain.com

# å®‰å…¨é…ç½®
NEXTAUTH_SECRET=ç”Ÿäº§ç¯å¢ƒéšæœºå¯†é’¥
JWT_SECRET=ç”Ÿäº§ç¯å¢ƒJWTå¯†é’¥

# æ•°æ®åº“ (æ¨èäº‘æœåŠ¡)
DATABASE_URL="postgresql://user:pass@prod-db.com:5432/study_assistant?sslmode=require"

# æ–‡ä»¶å­˜å‚¨ (AWS S3)
STORAGE_TYPE=s3
AWS_ACCESS_KEY_ID=ä½ çš„AWSè®¿é—®å¯†é’¥
AWS_SECRET_ACCESS_KEY=ä½ çš„AWSç§˜å¯†å¯†é’¥
AWS_REGION=us-west-2
AWS_BUCKET_NAME=study-assistant-prod
```

## ğŸ“Š æ•°æ®åº“ç®¡ç†

### å¸¸ç”¨æ•°æ®åº“å‘½ä»¤
```bash
# æ•°æ®åº“è¿ç§»
npm run db:generate       # ç”ŸæˆPrismaå®¢æˆ·ç«¯
npm run db:migrate        # è¿è¡Œè¿ç§»
npm run db:reset         # é‡ç½®æ•°æ®åº“(å±é™©!)
npm run db:seed          # åˆå§‹åŒ–æµ‹è¯•æ•°æ®

# æ•°æ®åº“çŠ¶æ€æ£€æŸ¥
npm run db:status        # æŸ¥çœ‹è¿ç§»çŠ¶æ€
npm run db:studio        # æ‰“å¼€Prisma Studio
```

### æ•°æ®åº“ç»´æŠ¤
```bash
# å¤‡ä»½æ•°æ®åº“
pg_dump -h localhost -U postgres study_assistant > backup.sql

# æ¢å¤æ•°æ®åº“  
psql -h localhost -U postgres study_assistant < backup.sql

# æŸ¥çœ‹æ•°æ®åº“å¤§å°
psql -h localhost -U postgres -c "
  SELECT schemaname, tablename, 
         pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
  FROM pg_tables 
  WHERE schemaname = 'public'
  ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
"
```

### pgvector ç»´æŠ¤
```bash
# é‡å»ºå‘é‡ç´¢å¼• (æ€§èƒ½ä¼˜åŒ–)
psql -h localhost -U postgres study_assistant -c "
  REINDEX INDEX segments_embedding_cosine_idx;
"

# æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
psql -h localhost -U postgres study_assistant -c "
  SELECT indexname, idx_scan, idx_tup_read, idx_tup_fetch
  FROM pg_stat_user_indexes
  WHERE indexname LIKE '%embedding%';
"

# å‘é‡æœç´¢æ€§èƒ½æµ‹è¯•
psql -h localhost -U postgres study_assistant -c "
  EXPLAIN ANALYZE 
  SELECT id, content, embedding <=> '[0,1,0...]' as distance
  FROM segments 
  ORDER BY embedding <=> '[0,1,0...]' 
  LIMIT 10;
"
```

## ğŸ³ Docker éƒ¨ç½²

### æœ¬åœ°Dockerå¼€å‘
```bash
# æ„å»ºæ‰€æœ‰æœåŠ¡
docker-compose -f docker-compose.dev.yml build

# å¯åŠ¨å¼€å‘ç¯å¢ƒ
docker-compose -f docker-compose.dev.yml up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose -f docker-compose.dev.yml logs -f web

# åœæ­¢æœåŠ¡
docker-compose -f docker-compose.dev.yml down
```

### ç”Ÿäº§Dockeréƒ¨ç½²
```bash
# æ„å»ºç”Ÿäº§é•œåƒ
docker build -t study-assistant:latest .

# è¿è¡Œç”Ÿäº§å®¹å™¨
docker run -d \
  --name study-assistant \
  -p 3000:3000 \
  -e DATABASE_URL="your-prod-db-url" \
  -e OPENAI_API_KEY="your-api-key" \
  study-assistant:latest
```

## â˜ï¸ äº‘ç«¯éƒ¨ç½²

### Vercel éƒ¨ç½² (æ¨èå‰ç«¯)
```bash
# å®‰è£…Vercel CLI
npm i -g vercel

# éƒ¨ç½²
vercel --prod

# é…ç½®ç¯å¢ƒå˜é‡ (åœ¨Vercel Dashboard)
NEXTAUTH_SECRET=ç”Ÿäº§å¯†é’¥
DATABASE_URL=æ•°æ®åº“è¿æ¥ä¸²
OPENAI_API_KEY=OpenAIå¯†é’¥
```

### AWS/Railway éƒ¨ç½² (åç«¯æœåŠ¡)
```bash
# æ„å»ºåº”ç”¨
npm run build

# è®¾ç½®ç¯å¢ƒå˜é‡
export NODE_ENV=production
export DATABASE_URL="ç”Ÿäº§æ•°æ®åº“URL"
export REDIS_URL="ç”Ÿäº§Redis URL"

# å¯åŠ¨ç”Ÿäº§æœåŠ¡
npm start
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### å¥åº·æ£€æŸ¥ç«¯ç‚¹
```bash
# APIå¥åº·æ£€æŸ¥
curl http://localhost:4000/health

# æ•°æ®åº“è¿æ¥æ£€æŸ¥  
curl http://localhost:4000/health/db

# Redisè¿æ¥æ£€æŸ¥
curl http://localhost:4000/health/redis
```

### æ—¥å¿—æ”¶é›†
```bash
# åº”ç”¨æ—¥å¿—
pm2 logs study-assistant

# æ•°æ®åº“æ—¥å¿—
tail -f /var/log/postgresql/postgresql-15-main.log

# Nginxè®¿é—®æ—¥å¿—
tail -f /var/log/nginx/access.log
```

### æ€§èƒ½ç›‘æ§
```bash
# CPUå’Œå†…å­˜ä½¿ç”¨
htop

# æ•°æ®åº“è¿æ¥æ•°
psql -h localhost -U postgres -c "
  SELECT count(*) as connections, state 
  FROM pg_stat_activity 
  WHERE datname = 'study_assistant' 
  GROUP BY state;
"

# Rediså†…å­˜ä½¿ç”¨
redis-cli info memory
```

## ğŸ”„ å¤‡ä»½å’Œæ¢å¤

### è‡ªåŠ¨å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# backup.sh
BACKUP_DIR="/var/backups/study-assistant"
DATE=$(date +%Y%m%d_%H%M%S)

# æ•°æ®åº“å¤‡ä»½
pg_dump -h localhost -U postgres study_assistant > \
  $BACKUP_DIR/db_backup_$DATE.sql

# æ–‡ä»¶å¤‡ä»½ (MinIO/S3)
aws s3 sync s3://study-assistant-bucket \
  $BACKUP_DIR/files_$DATE/

# æ¸…ç†æ—§å¤‡ä»½ (ä¿ç•™7å¤©)
find $BACKUP_DIR -name "*.sql" -mtime +7 -delete
find $BACKUP_DIR -name "files_*" -mtime +7 -exec rm -rf {} \;
```

### æ¢å¤æµç¨‹
```bash
# 1. åœæ­¢åº”ç”¨æœåŠ¡
pm2 stop study-assistant

# 2. æ¢å¤æ•°æ®åº“
psql -h localhost -U postgres study_assistant < backup.sql

# 3. æ¢å¤æ–‡ä»¶
aws s3 sync backup/files/ s3://study-assistant-bucket/

# 4. é‡å¯æœåŠ¡
pm2 restart study-assistant
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

#### 1. æ•°æ®åº“è¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥PostgreSQLçŠ¶æ€
systemctl status postgresql

# æ£€æŸ¥è¿æ¥é…ç½®
psql -h localhost -U postgres study_assistant

# æ£€æŸ¥pgvectoræ‰©å±•
psql -h localhost -U postgres -c "SELECT * FROM pg_extension WHERE extname = 'vector';"
```

#### 2. NextAuthè®¤è¯é—®é¢˜
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $NEXTAUTH_SECRET
echo $NEXTAUTH_URL

# æ£€æŸ¥æ•°æ®åº“è¡¨
psql -h localhost -U postgres study_assistant -c "
  SELECT tablename FROM pg_tables 
  WHERE tablename IN ('accounts', 'sessions', 'users');
"
```

#### 3. æ–‡ä»¶ä¸Šä¼ å¤±è´¥
```bash
# æ£€æŸ¥MinIOçŠ¶æ€
curl http://localhost:9000/minio/health/live

# æ£€æŸ¥å­˜å‚¨ç©ºé—´
df -h

# æ£€æŸ¥æ–‡ä»¶æƒé™
ls -la uploads/
```

#### 4. AI APIè°ƒç”¨å¤±è´¥
```bash
# æµ‹è¯•OpenAIè¿æ¥
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
  https://api.openai.com/v1/models

# æ£€æŸ¥APIé…é¢
# ç™»å½• https://platform.openai.com/account/usage
```

### æ€§èƒ½ä¼˜åŒ–
```bash
# æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–
npm run db:analyze

# æ¸…ç†ç¼“å­˜
redis-cli FLUSHALL

# é‡å¯åº”ç”¨é‡Šæ”¾å†…å­˜
pm2 restart study-assistant
```

---

**ğŸ“ æ›´æ–°è¯´æ˜**: è¿ç»´æ–‡æ¡£éšéƒ¨ç½²ç¯å¢ƒå˜åŒ–æ›´æ–°ï¼Œé‡è¦é…ç½®å˜æ›´éœ€è¦é€šçŸ¥æ‰€æœ‰å¼€å‘è€…ã€‚